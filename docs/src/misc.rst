=============
Miscellaneous
=============

Benchmark comparison
^^^^^^^^^^^^^^^^^^^^

In the companion `JOSS <https://joss.theoj.org/>`_
`paper <https://joss.theoj.org/papers/bc6892f6873808ced10bc8c4c222e635>`_
AMaze is compared against a number of other benchmarks from the Python ecosystem.
The scripts (Python and Shell) to reproduce a under `docs/latex/benchmarking`:

- `generate_all.sh` iterates over every declared package and proceeds, if necessary, to
  installing it before delegating to the dedicated worker.
- The full list of workers is:

  .. literalinclude:: ../latex/benchmarking/generate_all.sh
    :linenos:
    :lines: 11-20

- Individual workers will perform 1000 timesteps of every available environment (averaged
  over 10 replicates) in the inspected library and report through a pandas dataframe

- `format.py` performs the formatting of the raw data thus produced.
  Note that the one used for the aforementioned article is available under
  `docs/latex/benchmarking/table.csv`


Complexity space
^^^^^^^^^^^^^^^^

In the README, a figure presenting the complexity of 500'000 mazes is used to showcase the
diversity of the underlying space.
Such a figure can be generated by????

Build Errors
^^^^^^^^^^^^
.. include:: _autogen/errors.rst
