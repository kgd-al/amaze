=============
Miscellaneous
=============

Benchmark comparison
^^^^^^^^^^^^^^^^^^^^

In the companion `JOSS <https://joss.theoj.org/>`_
`paper <https://joss.theoj.org/papers/bc6892f6873808ced10bc8c4c222e635>`_
AMaze is compared against a number of other benchmarks from the Python ecosystem.
The scripts (Python and Shell) to reproduce a under `docs/latex/benchmarking`:

- `generate_all.sh` iterates over every declared package and proceeds, if necessary, to
  installing it before delegating to the dedicated worker.
- The full list of workers is:

  .. literalinclude:: ../latex/benchmarking/generate_all.sh
    :linenos:
    :lines: 11-20

- Individual workers will perform 1000 timesteps of every available environment (averaged
  over 10 replicates) in the inspected library and report through a pandas dataframe

- `format.py` performs the formatting of the raw data thus produced.
  Note that the one used for the aforementioned article is available under
  `docs/latex/benchmarking/table.csv`

.. warning::

    Installing all of these libraries plus their dependencies *will* take quite some time
    and disk space.
    It is *highly* recommended to do so in a virtual environment on a sufficiently robust
    machine.

Complexity space
^^^^^^^^^^^^^^^^

In the README, a figure presenting the complexity of 500'000 mazes is used to showcase the
diversity of the underlying space.
Such a figure can be generated by the scripts under `docs/latex/complexity/`:

- `generate.py` will create 100'000 mazes of Trivial, Simple, Lures, Traps and Complex classes,
  each.
  Results are stored in the sibling file `data.csv`

- `format.py` will generate most of the visuals (kde, image overlay)

- `complexity.tex` needs to be compiled for the inset images (it is recommended to do so
  from the main compiler at `docs/latex/compile.sh`

Build Errors
^^^^^^^^^^^^
.. include:: _autogen/errors.rst
